{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CgARbw74fNT",
        "outputId": "6f99a7a5-8746-432a-8262-d1a4dccb95ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 ... 1 0 1]\n",
            "0.784872\n",
            "28.255392\n",
            "3.139488\n",
            "0.96358323097229\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import numba\n",
        "from numba import cuda\n",
        "from random import seed, random\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "r = 3\n",
        "w = 2 * r\n",
        "arr_size = 2000000\n",
        "\n",
        "r_arr_x = np.random.uniform(0, w, size=arr_size)\n",
        "r_arr_y = np.random.uniform(0, w, size=arr_size)\n",
        "#print(r_arr_x)\n",
        "#print(r_arr_y)\n",
        "@cuda.jit\n",
        "def in_circle(r, d_arr, r_arr_x, r_arr_y):\n",
        "\n",
        "    i = ((cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x)) \n",
        "\n",
        "    x = r_arr_x[i] \n",
        "    y = r_arr_y[i] \n",
        "\n",
        "    d = ((x-r)**2 + (y - r)**2)**(1/2)\n",
        "\n",
        "    if d < r:\n",
        "        d_arr[i] = 1\n",
        "    else:\n",
        "        d_arr[i] = 0\n",
        "\n",
        "\n",
        "arr = np.full(arr_size, r)\n",
        "d_arr = cuda.to_device(arr)\n",
        "\n",
        "threads_per_block = 1\n",
        "blocks_per_grid = (arr.size + (threads_per_block - 1)) // threads_per_block\n",
        "\n",
        "\n",
        "in_circle[blocks_per_grid, threads_per_block](r, d_arr, r_arr_x, r_arr_y)\n",
        "\n",
        "result_array = d_arr.copy_to_host()\n",
        "\n",
        "print(result_array)\n",
        "\n",
        "zeros = 0\n",
        "ones = 0\n",
        "for j in range(arr_size):\n",
        "\n",
        "  if result_array[j] == 0:\n",
        "    zeros = zeros + 1\n",
        "  else:\n",
        "    ones = ones + 1\n",
        "\n",
        "ratio = ones / arr_size\n",
        "area = ratio * w**2\n",
        "pi = (area / (r**2))\n",
        "\n",
        "print(ratio)\n",
        "print(area)\n",
        "print(pi)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    }
  ]
}